# -*- coding: utf-8 -*-
"""CA_Heart_Attack_Risk_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QGDDu7yN-ksZUbvzOVLbKdyn0r1DAIZj

**Importing Important Libraries Required**
"""

import numpy as np  # Import NumPy for numerical operations

import pandas as pd  # Import Pandas for data manipulation and analysis

from sklearn.preprocessing import StandardScaler  # Import StandardScaler to normalize feature values

from sklearn.model_selection import GridSearchCV  # Import GridSearchCV for hyperparameter tuning

from imblearn.over_sampling import SMOTE  # Import SMOTE to handle class imbalance (Install with: pip install imblearn)

from imblearn.pipeline import Pipeline  # Import Pipeline to streamline multiple preprocessing steps

from sklearn.linear_model import SGDClassifier  # Import Stochastic Gradient Descent classifier

from sklearn.svm import SVC  # Import Support Vector Classifier for classification tasks

from sklearn.naive_bayes import MultinomialNB  # Import Na√Øve Bayes classifier, often used for text classification

from sklearn import metrics  # Import metrics module for evaluating model performance

from sklearn.linear_model import SGDClassifier  # (Duplicate Import) SGDClassifier is already imported above

import joblib  # Import Joblib to save and load trained models efficiently

import warnings  # Import warnings module to handle warning messages

warnings.filterwarnings("ignore", category=FutureWarning)  # Suppress future warnings to keep the output clean

from sklearn.impute import SimpleImputer  # Import SimpleImputer to handle missing values in the dataset

from sklearn.neural_network import MLPClassifier  # Import MLPClassifier to build a Neural Network model

from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer  # Import various scoring metrics

from sklearn.metrics import confusion_matrix  # Import confusion matrix to evaluate classification performance

import seaborn as sns  # Import Seaborn for data visualization and statistical plots

import matplotlib.pyplot as plt  # Import Matplotlib for plotting graphs

from sklearn.model_selection import train_test_split  # Import train_test_split to split dataset into training and testing sets

from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder to convert categorical labels into numerical format

"""**Data Preparation**"""

file_path= '/content/CA_Dataset.csv' # Define the file path for the dataset

dataset=pd.read_csv(file_path) # Load the dataset into a Pandas DataFrame

dataset.head() # Display the first few rows of the dataset

dataset.shape # Print the number of rows and columns in the dataset

dataset.isnull().sum() # Count the missing values in each column

dataset.info() # Display summary information about the dataset, including data types and missing values

# Splitting the 'Blood Pressure' column into 'Systolic' and 'Diastolic' columns
dataset[['Systolic', 'Diastolic']] = dataset['Blood Pressure'].str.split('/', expand=True)

# Convert 'Systolic' and 'Diastolic' columns from string to numeric format
dataset['Systolic'] = pd.to_numeric(dataset['Systolic'])
dataset['Diastolic'] = pd.to_numeric(dataset['Diastolic'])

# Remove the original 'Blood Pressure' column as it's now redundant
dataset.drop(columns=['Blood Pressure'], inplace=True)

dataset.info()

# Print unique values in categorical columns to understand their distribution
print(dataset['Sex'].unique())
print(dataset['Family History'].unique())
print(dataset['Smoking'].unique())
print(dataset['Alcohol Consumption'].unique())
print(dataset['Diet'].unique())
print(dataset['Previous Heart Problems'].unique())
print(dataset['Medication Use'].unique())
print(dataset['Country'].unique())
print(dataset['Continent'].unique())
print(dataset['Hemisphere'].unique())
print(dataset['Heart Attack Risk'].unique())

dataset['Sex']=dataset['Sex'].map({'Male':1,'Female':0}) # Convert categorical values to numerical format for machine learning models

dataset['Family History']=dataset['Family History'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset['Smoking']=dataset['Smoking'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset['Alcohol Consumption']=dataset['Alcohol Consumption'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset['Diet']=dataset['Diet'].map({'Unhealthy':0,'Average':1,'Healthy':2}) # Convert categorical values to numerical format for machine learning models

dataset['Previous Heart Problems']=dataset['Previous Heart Problems'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset['Medication Use']=dataset['Medication Use'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset['Heart Attack Risk']=dataset['Heart Attack Risk'].map({'Yes':1,'No':0}) # Convert categorical values to numerical format for machine learning models

dataset.drop(columns=['Country','Patient ID'], inplace=True) # Remove columns that are not relevant for modeling

df=pd.get_dummies(dataset,columns=['Continent','Hemisphere']) # Convert categorical columns ('Continent' and 'Hemisphere') into dummy/one-hot encoded variables

df.info()

# Define feature set (X) and target variable (y)
x=df.drop(['Heart Attack Risk'],axis=1) # Features (independent variables)
y=df['Heart Attack Risk'] # Target variable (dependent variable

x.shape

y.shape

"""**Data Scaling**"""

# Normalizing numerical features so that each feature has mean 0 and variance 1

feature_scaler = StandardScaler()
x_scaled = feature_scaler.fit_transform(x)

"""**Buliding test and train data by splitting the data in test and train**"""

# Import the model_selection module from the sklearn (scikit-learn) library
# and give it the call function 'sm' for easy reference
import sklearn.model_selection as sm

"""**Splitting Dataset**"""

# Split the dataset into training and testing sets.
# The test size is set to 30%, meaning 70% of the data will be used for training and 30% for testing.
# 'random_state=42' ensures the split is reproducible with the same data each time the code is run.
x_train, x_test, y_train, y_test= sm.train_test_split(x_scaled,y, test_size=0.2, random_state=1)

x_train.shape

x_test.shape

y_train.value_counts() # This code counts the occurrences of each unique value in the y_train Series

# Data Balancing

# Importing SMOTE (Synthetic Minority Over-sampling Technique) to address class imbalance by generating synthetic samples for the minority class.
from imblearn.over_sampling import SMOTE # Function SMOTE imported for data balancing

# Apply SMOTE (Synthetic Minority Over-sampling Technique) to balance the classes in the training dataset.
# This technique generates synthetic samples for the minority class to address class imbalance.
# 'random_state=42' ensures reproducibility of the resampling process.
x_train,y_train=SMOTE(random_state=42).fit_resample(x_train,y_train) # Balancing the class labels

y_train.value_counts()

"""**Apply Classification Algorithms**

**Logistic Regression**
"""

# Implementing Logistic Regression

# Tuning eta0, max_iter, alpha, and l1_ratio parameters and implementing cross-validation using Grid Search

model = Pipeline([
        ('imputation', SimpleImputer(strategy='mean')),
        ('balancing', SMOTE(random_state = 101)),   # Synthetic Minority Oversampling Technique

        ('classification', SGDClassifier(loss = 'log_loss', penalty = 'elasticnet', random_state = 1))

    ])

grid_param = {'classification__eta0': [.001,.01,0.1,1,10,100], 'classification__max_iter' : [100,200,400,500,600,700,900,1000], 'classification__alpha': [.001, .01,.1, 1,10,100], 'classification__l1_ratio': [0,0.3,0.5,0.7,1]}

gd_sr = GridSearchCV(estimator=model, param_grid=grid_param, scoring='recall', cv=5)

gd_sr.fit(x_train, y_train)

best_parameters = gd_sr.best_params_

print("Best parameters: ", best_parameters)

best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
print(best_result)

print(f"Logistic Regression Best recall (using GridSearchCV): {best_result:.4f}")

# Get the predictions on the validation sets
y_pred_val = gd_sr.predict(x_test)  # Predict on the test data

# Calculate metrics on the validation sets
accuracy_val = accuracy_score(y_test, y_pred_val)
precision_val = precision_score(y_test, y_pred_val)
recall_val = recall_score(y_test, y_pred_val)

print(f"Logistic Regression Accuracy on validation set: {accuracy_val:.4f}")
print(f"Logistic Regression Precision on validation set: {precision_val:.4f}")
print(f"Logistic Regression Recall on validation set: {recall_val:.4f}")

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred_val)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Logistic Regression Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# Extract TP, TN, FP, FN
TN, FP, FN, TP = cm.ravel()
print(f"SVC True Positives (TP): {TP}")
print(f"SVC True Negatives (TN): {TN}")
print(f"SVC False Positives (FP): {FP}")
print(f"SVC False Negatives (FN): {FN}")

"""**XG Boosting**"""

from xgboost import XGBClassifier # import the XGBClassifier

model = Pipeline([
    ('imputation', SimpleImputer(strategy='mean')),  # Handle missing values
    ('balancing', SMOTE(random_state=101)),  # Handle class imbalance
    ('classification', XGBClassifier(random_state=1))  # Gradient Boosting
])

# Define hyperparameter grid
grid_param = {
    'classification__n_estimators': [10,12,15,18,20],  # Number of trees
    'classification__learning_rate': [0.01, 0.1, 0.2,0.3,0.4],  # Learning rate
    'classification__max_depth': [3,5,7,9,11],  # Depth of trees
}

# Grid Search with 5-fold CV (Optimized for Recall)
gd_sr_GB = GridSearchCV(estimator=model, param_grid=grid_param, scoring='recall', cv=5)

gd_sr_GB.fit(x_train, y_train)

# Best Parameters & Best Recall Score
best_parameters = gd_sr_GB.best_params_
print("Best Parameters:", best_parameters)

best_result = gd_sr_GB.best_score_  # Best recall score from cross-validation
print(f"Gradient Boosting Best Recall (using GridSearchCV): {best_result:.4f}")

# Get predictions on entire dataset
y_pred_val = gd_sr_GB.predict(x_test)

# Calculate performance metrics
accuracy_val = accuracy_score(y_test, y_pred_val)
precision_val = precision_score(y_test, y_pred_val)
recall_val = recall_score(y_test, y_pred_val)

print(f"Gradient Boosting Accuracy on validation set: {accuracy_val:.4f}")
print(f"Gradient Boosting Precision on validation set: {precision_val:.4f}")
print(f"Gradient Boosting Recall on validation set: {recall_val:.4f}")

# Display the confusion matrix
  cm_gd_sr_GB = confusion_matrix(y_test, y_pred_val)
  plt.figure(figsize=(8, 6))
  sns.heatmap(cm_gd_sr_GB, annot=True, fmt="d", cmap="Blues")
  plt.title("XGBoosting Confusion Matrix")
  plt.xlabel("Predicted Labels")
  plt.ylabel("True Labels")
  plt.show()

# Extract TP, TN, FP, FN
TN, FP, FN, TP = cm_gd_sr_GB.ravel()
print(f"XGBoosting True Positives (TP): {TP}")
print(f"XGBoosting True Negatives (TN): {TN}")
print(f"XGBoosting False Positives (FP): {FP}")
print(f"XGBoosting False Negatives (FN): {FN}")

"""**K Nearest neibhour**"""

from sklearn.neighbors import KNeighborsClassifier

# Define pipeline with imputation, SMOTE, and KNN classifier
model = Pipeline([
    ('imputation', SimpleImputer(strategy='mean')),  # Handle missing values
    ('balancing', SMOTE(random_state=101)),  # Handle class imbalance
    ('classification', KNeighborsClassifier())  # KNN classifier
])

# Define hyperparameters for tuning
grid_param = {
    'classification__n_neighbors': [3, 5, 7, 10],  # Test different K values
    'classification__weights': ['uniform', 'distance'],  # Weighting methods
    'classification__metric': ['euclidean', 'manhattan']  # Distance metrics
}

# Grid search with cross-validation
gd_sr_KNN = GridSearchCV(estimator=model, param_grid=grid_param, scoring='recall', cv=5)
gd_sr_KNN.fit(x_train, y_train)

# Get best parameters & best recall score
best_parameters = gd_sr_KNN.best_params_
print("Best Parameters:", best_parameters)
best_result = gd_sr_KNN.best_score_
print(f"Best Recall (using GridSearchCV): {best_result:.4f}")

# Get predictions on the entire dataset
y_pred_val = gd_sr_KNN.predict(x_test)

# Calculate evaluation metrics
accuracy_val = accuracy_score(y_test, y_pred_val)
precision_val = precision_score(y_test, y_pred_val)
recall_val = recall_score(y_test, y_pred_val)

print(f"KNN Accuracy on validation set: {accuracy_val:.4f}")
print(f"KNN Precision on validation set: {precision_val:.4f}")
print(f"KNN Recall on validation set: {recall_val:.4f}")

# Display the confusion matrix
  cm_KNN = confusion_matrix(y_test, y_pred_val)
  plt.figure(figsize=(8, 6))
  sns.heatmap(cm_KNN, annot=True, fmt="d", cmap="Blues")
  plt.title("KNN Confusion Matrix")
  plt.xlabel("Predicted Labels")
  plt.ylabel("True Labels")
  plt.show()

_# Extract TP, TN, FP, FN
TN, FP, FN, TP = cm_KNN.ravel()
print(f"KNN True Positives (TP): {TP}")
print(f"KNN True Negatives (TN): {TN}")
print(f"KNN False Positives (FP): {FP}")
print(f"KNN False Negatives (FN): {FN}")

# Based on Recall Value XGboosting is best performing model , so calculating the significannt predictaors.

featimp = pd.Series(gd_sr_GB.best_estimator_.named_steps["classification"].feature_importances_, index=list(x)).sort_values(ascending=False) # Getting feature importances list for the best model
print(featimp)